{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8952345,"sourceType":"datasetVersion","datasetId":5387626}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Let's make a Binary Tumor Classifier using Deep Learning and Pytorch**\n\nOur main focus is getting a model than can classify benign and malignant tumors just by looking at an image\n\nFor this project we will be working with the ISIC dataset, in this case a small subset with a bit less than 400 images classified in a CSV file as malignant or benign. \n\n(Available right here:  [https://challenge.isic-archive.com/data/](http://))\n\nFirst, we'll define the objective, getting at least 70% accuracy for our baseline(a baseline is just a first prototype) that we'll later train to over 95% accuracy.\n\nIn this notebook you will learn how:\n\n*     Prepare the metadata from a CSV (**C**omma **S**eparated **V**alues) file\n\n*     Use different techniques so we can get enough data (more on this later)\n\n*     Create a CustomDataset class so we can create our DataLoaders (DataLoaders are split into Training and Validation, more on this later)    \n\n*     Briefly go over the concept of how a Neural Network learns and how Gradient Descent and Loss functions work\n\n*     Define the training and validation functions to assess our model's effectiveness\n\n*     Choose what kind of architecture/pretrained model we will use for this task\n\n*     Train our baseline-model so it can reach our objective accuracy of 80%","metadata":{}},{"cell_type":"markdown","source":"# Preparing the data and metadata","metadata":{}},{"cell_type":"markdown","source":"Here we'll import the necessary libraries:","metadata":{}},{"cell_type":"code","source":"!pip install torch-summary\n!pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:31:48.727319Z","iopub.execute_input":"2024-08-10T08:31:48.727672Z","iopub.status.idle":"2024-08-10T08:32:15.210091Z","shell.execute_reply.started":"2024-08-10T08:31:48.727640Z","shell.execute_reply":"2024-08-10T08:32:15.208979Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\nDownloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.7)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.23.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom pathlib import Path\nimport pandas as pd\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:15.212118Z","iopub.execute_input":"2024-08-10T08:32:15.212433Z","iopub.status.idle":"2024-08-10T08:32:20.452224Z","shell.execute_reply.started":"2024-08-10T08:32:15.212403Z","shell.execute_reply":"2024-08-10T08:32:20.451415Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Define the paths to our images and our csv file, We'll be working with **Kaggle**, an ML competition site with free **GPU's** to train models faster.","metadata":{}},{"cell_type":"code","source":"image_path = Path('/kaggle/input/isic-small/ISIC-images')\ncsv_path = Path('/kaggle/input/isic-small/ISIC-images/metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:20.457645Z","iopub.execute_input":"2024-08-10T08:32:20.457910Z","iopub.status.idle":"2024-08-10T08:32:20.462175Z","shell.execute_reply.started":"2024-08-10T08:32:20.457885Z","shell.execute_reply":"2024-08-10T08:32:20.461316Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We read the CSV file with *pandas* (imported as ***pd***) and print the first lines.","metadata":{}},{"cell_type":"code","source":"# Read the csv file\nmetadata_df = pd.read_csv(csv_path)\nmetadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:20.463243Z","iopub.execute_input":"2024-08-10T08:32:20.463501Z","iopub.status.idle":"2024-08-10T08:32:20.515603Z","shell.execute_reply.started":"2024-08-10T08:32:20.463478Z","shell.execute_reply":"2024-08-10T08:32:20.514749Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        isic_id attribution copyright_license  age_approx anatom_site_general  \\\n0  ISIC_0000003   Anonymous              CC-0        30.0     upper extremity   \n1  ISIC_0000012   Anonymous              CC-0        30.0     posterior torso   \n2  ISIC_0000013   Anonymous              CC-0        30.0     posterior torso   \n3  ISIC_0000014   Anonymous              CC-0        35.0     posterior torso   \n4  ISIC_0000015   Anonymous              CC-0        35.0     posterior torso   \n\n  benign_malignant  clin_size_long_diam_mm  concomitant_biopsy diagnosis  \\\n0           benign                     NaN               False     nevus   \n1           benign                     NaN               False     nevus   \n2        malignant                     NaN                True  melanoma   \n3           benign                     NaN               False     nevus   \n4           benign                     NaN               False     nevus   \n\n  diagnosis_confirm_type family_hx_mm   image_type melanocytic personal_hx_mm  \\\n0                    NaN          NaN  dermoscopic        True            NaN   \n1                    NaN          NaN  dermoscopic        True            NaN   \n2         histopathology          NaN  dermoscopic        True            NaN   \n3                    NaN          NaN  dermoscopic        True            NaN   \n4                    NaN          NaN  dermoscopic        True            NaN   \n\n      sex  \n0    male  \n1    male  \n2  female  \n3    male  \n4    male  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>attribution</th>\n      <th>copyright_license</th>\n      <th>age_approx</th>\n      <th>anatom_site_general</th>\n      <th>benign_malignant</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>concomitant_biopsy</th>\n      <th>diagnosis</th>\n      <th>diagnosis_confirm_type</th>\n      <th>family_hx_mm</th>\n      <th>image_type</th>\n      <th>melanocytic</th>\n      <th>personal_hx_mm</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000003</td>\n      <td>Anonymous</td>\n      <td>CC-0</td>\n      <td>30.0</td>\n      <td>upper extremity</td>\n      <td>benign</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>nevus</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dermoscopic</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000012</td>\n      <td>Anonymous</td>\n      <td>CC-0</td>\n      <td>30.0</td>\n      <td>posterior torso</td>\n      <td>benign</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>nevus</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dermoscopic</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000013</td>\n      <td>Anonymous</td>\n      <td>CC-0</td>\n      <td>30.0</td>\n      <td>posterior torso</td>\n      <td>malignant</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>melanoma</td>\n      <td>histopathology</td>\n      <td>NaN</td>\n      <td>dermoscopic</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000014</td>\n      <td>Anonymous</td>\n      <td>CC-0</td>\n      <td>35.0</td>\n      <td>posterior torso</td>\n      <td>benign</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>nevus</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dermoscopic</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000015</td>\n      <td>Anonymous</td>\n      <td>CC-0</td>\n      <td>35.0</td>\n      <td>posterior torso</td>\n      <td>benign</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>nevus</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dermoscopic</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"That's a lot of columns, for this problem we only care about the **'isic_id'** column and the **'benign_malignant'** column. Luckily, *pandas* allows us to throw away the other columns in just one line.\nWe will also print the value counts to see how many benign and how many malignant images we have:","metadata":{}},{"cell_type":"code","source":"metadata_df = metadata_df[['isic_id', 'benign_malignant']]\nprint(metadata_df['benign_malignant'].value_counts())\nmetadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:20.516922Z","iopub.execute_input":"2024-08-10T08:32:20.517348Z","iopub.status.idle":"2024-08-10T08:32:20.536697Z","shell.execute_reply.started":"2024-08-10T08:32:20.517316Z","shell.execute_reply":"2024-08-10T08:32:20.535890Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"benign_malignant\nbenign                     303\nmalignant                   73\nindeterminate                1\nindeterminate/malignant      1\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        isic_id benign_malignant\n0  ISIC_0000003           benign\n1  ISIC_0000012           benign\n2  ISIC_0000013        malignant\n3  ISIC_0000014           benign\n4  ISIC_0000015           benign","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>benign_malignant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000003</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000012</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000013</td>\n      <td>malignant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000014</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000015</td>\n      <td>benign</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"There are 303 benign images and 73 malignant images, we will have to oversample the malignant ones to get better results (oversampling is basically repeating images so we can balance the two classes). We also have to remove the indeterminate images as we are making a binary classification model.","metadata":{}},{"cell_type":"code","source":"# We remove the indeterminate values\nmetadata_df = metadata_df[(metadata_df['benign_malignant'] == 'benign') | (metadata_df['benign_malignant'] == 'malignant')]\nprint(metadata_df['benign_malignant'].value_counts())\nmetadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:20.537651Z","iopub.execute_input":"2024-08-10T08:32:20.537962Z","iopub.status.idle":"2024-08-10T08:32:20.555269Z","shell.execute_reply.started":"2024-08-10T08:32:20.537917Z","shell.execute_reply":"2024-08-10T08:32:20.554379Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"benign_malignant\nbenign       303\nmalignant     73\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        isic_id benign_malignant\n0  ISIC_0000003           benign\n1  ISIC_0000012           benign\n2  ISIC_0000013        malignant\n3  ISIC_0000014           benign\n4  ISIC_0000015           benign","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>benign_malignant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000003</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000012</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000013</td>\n      <td>malignant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000014</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000015</td>\n      <td>benign</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"After keeping only the relevant columns and images, we define our *get_image_path* function to return the path of each image. We create an **'image_path'** column and ensure that all rows in *metadata_df* have a valid image_path. We do this by creating an **'image_exists'** column and then dropping it after we're done.","metadata":{}},{"cell_type":"code","source":"# Define a function to return an image path\ndef get_image_path(isic_id):\n    return image_path / f\"{isic_id}.jpg\"\n\n# Create a image_path column\nmetadata_df['image_path'] = metadata_df['isic_id'].apply(get_image_path)\n\n# Ensure the image exists\nmetadata_df['image_exists'] = metadata_df['image_path'].apply(lambda x: x.exists())\n\n# Remove rows where images do not exist\nmetadata_df = metadata_df[metadata_df['image_exists']]\n\n# Remove the image_exists column\nmetadata_df = metadata_df.drop(columns = ['image_exists'])\n\nmetadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:20.556361Z","iopub.execute_input":"2024-08-10T08:32:20.556655Z","iopub.status.idle":"2024-08-10T08:32:21.022464Z","shell.execute_reply.started":"2024-08-10T08:32:20.556624Z","shell.execute_reply":"2024-08-10T08:32:21.021633Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        isic_id benign_malignant  \\\n0  ISIC_0000003           benign   \n1  ISIC_0000012           benign   \n2  ISIC_0000013        malignant   \n3  ISIC_0000014           benign   \n4  ISIC_0000015           benign   \n\n                                          image_path  \n0  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  \n1  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  \n2  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  \n3  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  \n4  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>benign_malignant</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000003</td>\n      <td>benign</td>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000012</td>\n      <td>benign</td>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000013</td>\n      <td>malignant</td>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000014</td>\n      <td>benign</td>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000015</td>\n      <td>benign</td>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"If we print the value_counts of the **benign_malignant** column:","metadata":{}},{"cell_type":"code","source":"metadata_df['benign_malignant'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.023785Z","iopub.execute_input":"2024-08-10T08:32:21.024517Z","iopub.status.idle":"2024-08-10T08:32:21.032797Z","shell.execute_reply.started":"2024-08-10T08:32:21.024482Z","shell.execute_reply":"2024-08-10T08:32:21.031830Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"benign_malignant\nbenign       303\nmalignant     73\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Balancing the classes","metadata":{}},{"cell_type":"markdown","source":"We can clearly see that there is a class imbalance. This means that there are a lot more images of the benign class than there are of the malignant class. To solve this we will use a technique called oversampling, where we basically repeat the malignant images until we have enough to make the imbalance less noticeable","metadata":{}},{"cell_type":"markdown","source":"To do this we will separate *metadata_df* into **benign_df** and **malignant_df**","metadata":{}},{"cell_type":"code","source":"benign_df = metadata_df[metadata_df['benign_malignant'] == 'benign']\nmalignant_df = metadata_df[metadata_df['benign_malignant'] == 'malignant']","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.037543Z","iopub.execute_input":"2024-08-10T08:32:21.038259Z","iopub.status.idle":"2024-08-10T08:32:21.046699Z","shell.execute_reply.started":"2024-08-10T08:32:21.038232Z","shell.execute_reply":"2024-08-10T08:32:21.045974Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"We now define a custom function to oversample images called *oversample_items*.\n\nThis function is a simple integer division added to a remainder to reach the target count.","metadata":{}},{"cell_type":"code","source":"# Define a custom function to oversample the malignant images\ndef oversample_items(items, target_count):\n    return (items * (target_count // len(items))) + items[:target_count % len(items)]","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.047754Z","iopub.execute_input":"2024-08-10T08:32:21.048447Z","iopub.status.idle":"2024-08-10T08:32:21.056608Z","shell.execute_reply.started":"2024-08-10T08:32:21.048420Z","shell.execute_reply":"2024-08-10T08:32:21.055730Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"> *(items * (target_count // len(items)))* multiplies the items, let items = [1,2,3], by the integer division of target_count / len(items). Let *target_count* be 10. This would multiply the list by 10//3 (which equals 3), making our original list [1,2,3,1,2,3,1,2,3].\n> \n> After this we add *items[:target_count % len(items)]* which in this case would be items[:1], which is equal to the first element of the list, in this case one. Our final list being [1,2,3,1,2,3,1,2,3,1].","metadata":{}},{"cell_type":"code","source":"# Desired number of augmented malignant images\noversampled_malignant = 200\n\n# Oversample the malignant image file paths\nmalignant_items_list = oversample_items(malignant_df['image_path'].to_list(), oversampled_malignant)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.057828Z","iopub.execute_input":"2024-08-10T08:32:21.058570Z","iopub.status.idle":"2024-08-10T08:32:21.066761Z","shell.execute_reply.started":"2024-08-10T08:32:21.058539Z","shell.execute_reply":"2024-08-10T08:32:21.065936Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"After calling the function to oversample the malignant items we can get *malignant_items_list* and concatenate it with **pd.concat** along with *benign_df*, creating a dataframe that holds the image_paths and the labels.","metadata":{}},{"cell_type":"code","source":"# Create a combined DataFrame\ncombined_df = pd.concat([\n    pd.DataFrame({'image_path': benign_df['image_path'], 'label': 'benign'}),\n    pd.DataFrame({'image_path': malignant_items_list, 'label': 'malignant'})\n])\ncombined_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.067871Z","iopub.execute_input":"2024-08-10T08:32:21.069152Z","iopub.status.idle":"2024-08-10T08:32:21.083451Z","shell.execute_reply.started":"2024-08-10T08:32:21.069127Z","shell.execute_reply":"2024-08-10T08:32:21.082535Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                          image_path   label\n0  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  benign\n1  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  benign\n3  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  benign\n4  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  benign\n5  /kaggle/input/isic-small/ISIC-images/ISIC_0000...  benign","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n      <td>benign</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>/kaggle/input/isic-small/ISIC-images/ISIC_0000...</td>\n      <td>benign</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we move on to step two. We create the *CustomDataset* class so we can later create the *Dataset* object and eventually create the *DataLoaders*.","metadata":{}},{"cell_type":"markdown","source":"# Creating the CustomDataset class and the DataLoaders","metadata":{}},{"cell_type":"code","source":"# Let's create the CustomDataset class so we can create the Dataset for our model\nclass CustomDataset(Dataset):\n    def __init__(self, image_paths, categories, transforms):\n        self.image_paths = image_paths\n        self.categories = categories\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = 1 if (self.categories[idx] == 'malignant') else 0\n        if self.transforms:\n            image = self.transforms(image)\n        label = torch.tensor(label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:32:21.084716Z","iopub.execute_input":"2024-08-10T08:32:21.085163Z","iopub.status.idle":"2024-08-10T08:32:21.095744Z","shell.execute_reply.started":"2024-08-10T08:32:21.085128Z","shell.execute_reply":"2024-08-10T08:32:21.095056Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Next, we convert all the values in the **'image_path'** column to a list, same for the **'label'** column, and we create our *CustomDataset* object with the pertinent transformations.","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\n\ntrain_transformss = transforms.Compose([\n    transforms.Resize((224, 224)), # Resize the image\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(degrees=20),\n    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nvalid_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nimages = combined_df['image_path'].to_list()\ncategories = combined_df['label'].to_list()\n\n# Split the dataset into training and validation as to only transform the training images\ntrain_images, valid_images, train_categories, valid_categories = train_test_split(\n    images, categories, test_size=0.2, random_state=42, stratify=categories\n)\n\ntrain_dataset = CustomDataset(images, categories, train_transformss)\nvalid_dataset = CustomDataset(valid_images, valid_categories, valid_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:35:15.333941Z","iopub.execute_input":"2024-08-10T08:35:15.334319Z","iopub.status.idle":"2024-08-10T08:35:15.349070Z","shell.execute_reply.started":"2024-08-10T08:35:15.334287Z","shell.execute_reply":"2024-08-10T08:35:15.347910Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"> The transformations defined are:\n>\n>     -Resize(height, width) which ensures all images are the same size.\n>\n>     -ToTensor(image) which turns the image into pixel values for all three channels(RGB).\n>\n>     -Normalize(mean, standard deviation) which applies normalization to the image tensor so the values are similar to what the model has seen. These are the standard values for ImageNet which have been used for models like ResNet.  \n\n\n>We have split the transforms as to not alter the validation dataset and only apply data augmentation in the training dataset.\nThe rest are just transformations to increase the variability in our model and its ability to generalize and correctly classify images it has not seen before.","metadata":{}},{"cell_type":"markdown","source":"Let's display an image tensor. We can fetch it from our *CustomDataset* object by calling the __getitem__ function and giving the index parameter a value, in this case the value 1.","metadata":{}},{"cell_type":"code","source":"from IPython.display import display\n\nimage, label = train_dataset.__getitem__(1)\ndisplay(image)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:35:19.246895Z","iopub.execute_input":"2024-08-10T08:35:19.247236Z","iopub.status.idle":"2024-08-10T08:35:19.275339Z","shell.execute_reply.started":"2024-08-10T08:35:19.247211Z","shell.execute_reply":"2024-08-10T08:35:19.274440Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"tensor([[[ 0.0227,  0.0227,  0.0741,  ..., -0.7650, -0.8164, -0.9192],\n         [ 0.0227, -0.0458,  0.1254,  ..., -0.6965, -0.7822, -0.8849],\n         [ 0.0398,  0.1083,  0.2111,  ..., -0.6965, -0.7822, -0.9020],\n         ...,\n         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n\n        [[ 0.1352,  0.1352,  0.1877,  ..., -0.6352, -0.6702, -0.7402],\n         [ 0.1001,  0.0476,  0.2052,  ..., -0.5826, -0.6527, -0.7577],\n         [ 0.0826,  0.1176,  0.2402,  ..., -0.5826, -0.6527, -0.7927],\n         ...,\n         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n\n        [[ 0.5834,  0.6008,  0.6356,  ...,  0.0431, -0.0267, -0.1312],\n         [ 0.5659,  0.4962,  0.6531,  ...,  0.0605, -0.0267, -0.1312],\n         [ 0.5659,  0.6008,  0.7054,  ...,  0.0605, -0.0267, -0.1487],\n         ...,\n         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])"},"metadata":{}}]},{"cell_type":"markdown","source":"We will now create our two **DataLoader** objects, one for training and one for validation. Our training and validation datasets are already split into 80% training and 20% validation","metadata":{}},{"cell_type":"markdown","source":"To create the Datasets and Dataloaders we will import from from *torch.utils.data* the **Dataset** and **Dataloader** objects.","metadata":{}},{"cell_type":"code","source":"# Create the Dataloaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)\n\nxb, yb = next(iter(train_loader))\nxb.shape, yb.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:35:22.008830Z","iopub.execute_input":"2024-08-10T08:35:22.009613Z","iopub.status.idle":"2024-08-10T08:35:22.947186Z","shell.execute_reply.started":"2024-08-10T08:35:22.009585Z","shell.execute_reply":"2024-08-10T08:35:22.946186Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 3, 224, 224]), torch.Size([32]))"},"metadata":{}}]},{"cell_type":"markdown","source":"The dataset is split into training and validation, and the DataLoader splits the dataset into batches to feed into the GPU which performs calculations (primarily matrix multiplication) at incredible speeds in the CUDA language.","metadata":{}},{"cell_type":"markdown","source":"Now we have to make a decision about the model we'll be using. We can make our own model using Pytorch or make use of **[transfer-learning](http://https://builtin.com/data-science/transfer-learning#:~:text=Transfer%20learning%20is%20the%20reuse,networks%20with%20comparatively%20little%20data.)** and fine-tune a pretrained model for this task.\n\nJust for the fun of it we will try both, but first let's define our neural network and understand how it works","metadata":{}},{"cell_type":"markdown","source":"# How does a simple Neural Network make a prediction?","metadata":{}},{"cell_type":"markdown","source":"We will make a model from scratch and see how it actually makes decisions.","metadata":{}},{"cell_type":"markdown","source":"To make a model from scratch with the least Pytorch functionalities possible we need to randomly initialize our model's parameters. A model's parameters are the weights and bias:\n* Weights: The weights are the strength of the connection between two neurons, determining how much the value of one neuron influences the second neuron. They shape how the neural network makes decisions and are learned during training.\n\n* Bias: The bias is an additional parameter in each neuron that allows the model to shift the activation function to fit the data better. It helps the model learn the patterns even when all the input features are zero, adding flexibility to the learning process.","metadata":{}},{"cell_type":"code","source":"def init_params(size, std=1.0):\n    return (torch.randn(size)*std).requires_grad_()\nweights = init_params((224*224*3, 2))\nbias = init_params(2)\nprint(weights.shape, bias.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:35:26.595857Z","iopub.execute_input":"2024-08-10T08:35:26.596582Z","iopub.status.idle":"2024-08-10T08:35:26.606398Z","shell.execute_reply.started":"2024-08-10T08:35:26.596545Z","shell.execute_reply":"2024-08-10T08:35:26.605419Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"torch.Size([150528, 2]) torch.Size([2])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We'll make our *weights* be a tensor of ([2, 128 * 128 * 3]) as we have two classes (benign and malignant), and our images are resized for 128 * 128 pixels in 3 *RGB* channels.\n\nWe initialize our *bias* to (2).","metadata":{}},{"cell_type":"markdown","source":"Now we're going to bring in the most useful operation in Deep Learning, the *dot product*, also called matrix multiplication. We're going to get every image's tensor and we're going to multiply it with the weights, and then, using [broadcasting](http://https://medium.com/@krinaljoshi/broadcasting-in-pytorch-fc438ee04cc5), add the bias. This way we're going to end up with a matrix that contains the probabilities for each class","metadata":{}},{"cell_type":"code","source":"def linearOne(image_batch):\n    # Flatten each image in the batch to shape (batch_size, height*width*3)\n    batch_size = image_batch.size(0)\n    image_batch = image_batch.view(batch_size, -1)  # Flatten each image while preserving batch size\n    return image_batch @ weights + bias  # Broadcasting will handle adding bias to each row\nxb, yb = next(iter(train_loader))\npredictions = linearOne(xb)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:06.389844Z","iopub.execute_input":"2024-08-10T08:36:06.390354Z","iopub.status.idle":"2024-08-10T08:36:07.609350Z","shell.execute_reply.started":"2024-08-10T08:36:06.390310Z","shell.execute_reply":"2024-08-10T08:36:07.608364Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"> The *'@'* symbol represents the dot product operation in Python.\n","metadata":{}},{"cell_type":"markdown","source":"*xb* is a batch from our training Dataloader. We pass the first image to our *linearOne* function, and we get back a matrix of two elements.","metadata":{}},{"cell_type":"markdown","source":"Let's see what's in *predictions[0]* :","metadata":{}},{"cell_type":"code","source":"for p in predictions[0]:\n    print(p)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:11.702697Z","iopub.execute_input":"2024-08-10T08:36:11.703638Z","iopub.status.idle":"2024-08-10T08:36:11.710277Z","shell.execute_reply.started":"2024-08-10T08:36:11.703597Z","shell.execute_reply":"2024-08-10T08:36:11.709123Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"tensor(-619.2442, grad_fn=<UnbindBackward0>)\ntensor(844.1592, grad_fn=<UnbindBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We get back two values for the first item, the first represents the *benign* class, and the second one represents the *malignant* class. The bigger value is the model's prediction.","metadata":{}},{"cell_type":"markdown","source":"# How does a Neural Network actually learn?\n\nA Neural Network(NN for short) does not actually learn, its parameters are improved by an algorithm called gradient descent. Let's define the function:","metadata":{}},{"cell_type":"code","source":"def calculate_gradient(images, labels, model):\n    predictions = model(images)\n    loss = loss_function(predictions, labels)\n    loss.backward()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:23.653851Z","iopub.execute_input":"2024-08-10T08:36:23.654217Z","iopub.status.idle":"2024-08-10T08:36:23.658922Z","shell.execute_reply.started":"2024-08-10T08:36:23.654188Z","shell.execute_reply":"2024-08-10T08:36:23.657977Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"What's actually going on in the function:\n\n**Get the predictions:**\n\n*predictions = model(images)*\n\n**Measure the prediction against the actual label:**\n\n*loss = loss_function(predictions, labels)*\n\n* **Loss Function**: The loss function measures how well or how poorly our model is doing.\n\n**Backpropagation:**\n\n*loss.backward()*\n\nWhen we call *loss.backward()*, PyTorch performs backpropagation, which is just a fancy word for calculating the gradients of the loss function.\n\n**Gradient**: The gradient is the derivative of the loss function with respect to the model's parameters (weights and biases). It tells us how much the loss function would change if we changed the parameters slightly.","metadata":{}},{"cell_type":"code","source":"def update_parameters(parameters, learning_rate):\n    for parameter in parameters:\n        parameter.data -= parameter.grad * learning_rate\n        parameter.grad.zero_()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:27.499924Z","iopub.execute_input":"2024-08-10T08:36:27.500276Z","iopub.status.idle":"2024-08-10T08:36:27.504722Z","shell.execute_reply.started":"2024-08-10T08:36:27.500249Z","shell.execute_reply":"2024-08-10T08:36:27.503857Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Now we update the parameters by subtracting from the originals their gradient multiplied by the learning rate. Think of the learning rate as the size of our steps to reach the lowest point of a valley while blindfolded, if we make our steps too big we'll skip the lowest point, if we make them too small it's going to take us a long time.\n\n>         parameter.data -= parameter.grad * learning_rate\n\n","metadata":{}},{"cell_type":"markdown","source":"We subtract from the original parameter as we're moving in the opposite direction of the gradient","metadata":{}},{"cell_type":"markdown","source":"After, we set the parameter's grad to zero after each iteration as they accumulate and can mess up the calculations\n>         parameter.grad.zero_()","metadata":{}},{"cell_type":"markdown","source":"# Training and Validation functions","metadata":{}},{"cell_type":"markdown","source":"Let's put it all together:","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, parameters):\n    for images, labels in train_loader:\n        calculate_gradient(images, labels, model)\n        update_parameters(parameters, learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:30.138675Z","iopub.execute_input":"2024-08-10T08:36:30.139287Z","iopub.status.idle":"2024-08-10T08:36:30.143625Z","shell.execute_reply.started":"2024-08-10T08:36:30.139258Z","shell.execute_reply":"2024-08-10T08:36:30.142760Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Parameters passed to the training function\n\n* **Model**: The model is the neural network architecture, that we have defined for the task at hand.\n\n* **Dataloader**: The Dataloader, simply put, splits our dataset into batches.\n\n* **Parameters**: The model's parameters (weight and bias), in this case initialized with the *init_params* function to a random value.","metadata":{}},{"cell_type":"markdown","source":"Ok, that's how our model's parameters get better and how it actually \"learns\", but we need to create two more functions to measure how good the performance is:\n\n*batch_accuracy*, which returns the accuracy of the batch.\n\n*validate_model*, which appends all the batches accuracy in a list and then returns the mean of all the items rounded to 4 decimals.","metadata":{}},{"cell_type":"code","source":"def batch_accuracy(predictions, labels):\n    predictions = predictions[:, 1].sigmoid()\n    correct = (predictions>0.5).float() == labels.float()\n    return correct.float().mean()\n\ndef validate_model(model, valid_dataloader):\n    accs = []\n    for images,labels in valid_dataloader:\n        accuracy = batch_accuracy(model(images), labels)\n        accs.append(accuracy)\n    return round(torch.stack(accs).mean().item(), 4)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:37.300670Z","iopub.execute_input":"2024-08-10T08:36:37.301282Z","iopub.status.idle":"2024-08-10T08:36:37.307481Z","shell.execute_reply.started":"2024-08-10T08:36:37.301251Z","shell.execute_reply":"2024-08-10T08:36:37.306559Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Ok, now that we have defined all the functions for our model to learn, let's define the parameters that we'll pass to train_model and validate_model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nmodel = linearOne\ntrain_loader = train_loader\nvalid_loader = valid_loader\nparameters = weights, bias\nlearning_rate = 1e-3\nloss_function = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:36:41.508763Z","iopub.execute_input":"2024-08-10T08:36:41.509104Z","iopub.status.idle":"2024-08-10T08:36:41.514366Z","shell.execute_reply.started":"2024-08-10T08:36:41.509076Z","shell.execute_reply":"2024-08-10T08:36:41.513286Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"For our loss function we will use nn.CrossEntropyLoss as it is ideal for binary classification\n\nOur learning rate is 0.001 as of now","metadata":{}},{"cell_type":"code","source":"xb, yb = next(iter(train_loader))\nxb.shape, yb.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:37:01.578891Z","iopub.execute_input":"2024-08-10T08:37:01.579354Z","iopub.status.idle":"2024-08-10T08:37:02.487099Z","shell.execute_reply.started":"2024-08-10T08:37:01.579316Z","shell.execute_reply":"2024-08-10T08:37:02.486157Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 3, 224, 224]), torch.Size([32]))"},"metadata":{}}]},{"cell_type":"markdown","source":"> It's always a good practice to get our dataloaders batch sizes to debug our model","metadata":{}},{"cell_type":"code","source":"for i in range(5):\n    train_model(model, train_loader, parameters)\n    print(validate_model(model, valid_loader))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:37:05.427864Z","iopub.execute_input":"2024-08-10T08:37:05.428767Z","iopub.status.idle":"2024-08-10T08:38:40.216319Z","shell.execute_reply.started":"2024-08-10T08:37:05.428732Z","shell.execute_reply":"2024-08-10T08:38:40.215354Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"0.4547\n0.5125\n0.5203\n0.5125\n0.5703\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Our model is not doing all that bad, with just one layer it can predict tumors at almost 60% accuracy, I tried with 128x128 images and the accuracy jumped up to 70%, with just one layer of matrix multiplication!! Let's add a couple more layers and see how it affects the accuracy:","metadata":{}},{"cell_type":"markdown","source":"Let's create a new architecture function:","metadata":{}},{"cell_type":"code","source":"def linearThree(image_batch):\n    # Flatten each image in the batch to shape (batch_size, height*width*3)\n    batch_size = image_batch.size(0)\n    image_batch = image_batch.view(batch_size, -1) # Flattened while preserving batch_size\n    layer_one = image_batch @ w1 + b1\n    layer_two = layer_one @ w2 + b2\n    layer_three = layer_two @ w3 + b3\n    return layer_three","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:39:03.144552Z","iopub.execute_input":"2024-08-10T08:39:03.145409Z","iopub.status.idle":"2024-08-10T08:39:03.150598Z","shell.execute_reply.started":"2024-08-10T08:39:03.145368Z","shell.execute_reply":"2024-08-10T08:39:03.149520Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"w1 = init_params((224*224*3, 256))\nb1 = init_params((256))\nw2 = init_params((256, 128))\nb2 = init_params((128))\nw3 = init_params((128, 2))\nb3 = init_params((2))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:39:18.292729Z","iopub.execute_input":"2024-08-10T08:39:18.293679Z","iopub.status.idle":"2024-08-10T08:39:18.754037Z","shell.execute_reply.started":"2024-08-10T08:39:18.293642Z","shell.execute_reply":"2024-08-10T08:39:18.753198Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"> We initialize 3 layers of weights, the values of 256 and 128 neurons for the hidden layers are random, but I have only seen ^2 numbers used for the middle layers.","metadata":{}},{"cell_type":"markdown","source":"Now we can try training it, we'll see if it actually improves or if the accuracy gets worse.","metadata":{}},{"cell_type":"code","source":"model = linearThree\nparameters = [w1, b1, w2, b2, w3, b3]\nlearning_rate = 1e-3\nloss_function = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:39:24.866787Z","iopub.execute_input":"2024-08-10T08:39:24.867403Z","iopub.status.idle":"2024-08-10T08:39:24.871906Z","shell.execute_reply.started":"2024-08-10T08:39:24.867368Z","shell.execute_reply":"2024-08-10T08:39:24.871006Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    train_model(model, train_loader, parameters)\n    print(validate_model(model, valid_loader))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:39:28.166813Z","iopub.execute_input":"2024-08-10T08:39:28.167741Z","iopub.status.idle":"2024-08-10T08:41:18.842657Z","shell.execute_reply.started":"2024-08-10T08:39:28.167703Z","shell.execute_reply":"2024-08-10T08:41:18.841716Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"0.5188\n0.5188\n0.5188\n0.5188\n0.5188\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Surprisingly, it has gotten worse. This could be due to a myriad of reasons, including but not limited to: missing learning rate adjustment, overfitting to the dataset as it is smaller than the model's capacity, vanishing gradients...","metadata":{}},{"cell_type":"markdown","source":"Now, let's make use of transfer-learning, which is just getting a pre-trained model on a large dataset (like ResNet which is trained on the ImageNet dataset), and fine-tune it for our specific task. Let's use a small architecture for efficiency reasons and since we've seen bigger != better.","metadata":{}},{"cell_type":"markdown","source":"We're going to have to automate our manual steps in our training and validation functions with Pytorch objects and functions, in this case, replace our manual gradient descent with an optimizer and add a few lines to fine-tune our pretrained model:","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, optimizer, loss_function):\n    model.train()\n    for images, labels in train_loader:\n        # CUDA\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(images)\n        loss = loss_function(predictions, labels)\n        loss.backward()\n        optimizer.step()\n\ndef batch_accuracy(predictions, labels):\n    predictions = predictions[:, 1].sigmoid()\n    correct = (predictions>0.5).float() == labels.float()\n    return correct.float().mean()\n\ndef validate_model(model, valid_dataloader):\n    model.eval()\n    accs = []\n    with torch.no_grad():\n        for images,labels in valid_dataloader:\n            # CUDA\n            images, labels = images.to(device), labels.to(device)\n            accuracy = batch_accuracy(model(images), labels)\n            accs.append(accuracy)\n    return round(torch.stack(accs).mean().item(), 4)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:41:29.488209Z","iopub.execute_input":"2024-08-10T08:41:29.488972Z","iopub.status.idle":"2024-08-10T08:41:29.497866Z","shell.execute_reply.started":"2024-08-10T08:41:29.488905Z","shell.execute_reply":"2024-08-10T08:41:29.496970Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Let's define our parameters to pass to the training and validation functions. We'll use the mobilenetV2 model and change its last layer to be of two neurons instead of 1000.","metadata":{}},{"cell_type":"code","source":"from torch import optim\nimport torchvision.models as models\nimport timm\n\n# Load pre-trained model\nmodel = models.mobilenet_v2(pretrained = True)\n# Get the number of input features for the classifier\nnum_features = model.classifier[1].in_features\n# Replace the last layer with a new Linear layer with 2 output features (for binary classification)\nmodel.classifier[1] = torch.nn.Linear(num_features, 2)\n\n# CUDA\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Using Pytorch functionalities\noptimizer = optim.SGD(model.parameters(), lr=5e-3)\nloss_function = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:46:00.470854Z","iopub.execute_input":"2024-08-10T08:46:00.471711Z","iopub.status.idle":"2024-08-10T08:46:00.599636Z","shell.execute_reply.started":"2024-08-10T08:46:00.471677Z","shell.execute_reply":"2024-08-10T08:46:00.598856Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"> In this block of code we have loaded our model and changed its last layer to be of 2 neurons, defined an optimizer and a loss_function and wrote a line to send the model to train on a GPU if available.","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    train_model(model, train_loader, optimizer, loss_function)\n    print(validate_model(model, valid_loader))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T08:46:06.357687Z","iopub.execute_input":"2024-08-10T08:46:06.358574Z","iopub.status.idle":"2024-08-10T08:49:20.449324Z","shell.execute_reply.started":"2024-08-10T08:46:06.358539Z","shell.execute_reply":"2024-08-10T08:49:20.448366Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"0.575\n0.6781\n0.7094\n0.8328\n0.8719\n0.8906\n0.875\n0.9219\n0.9609\n0.9609\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Our model reaches 96% accuracy, it may sound to good to be true but the only way of knowing if the model just overfitted is testing it with a test set or seeing how it evolves. The notebook is getting too long so let's just keep this as a baseline and feed it more data later.","metadata":{}},{"cell_type":"markdown","source":"Let's export our model to use it later:","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict, \"tumor_baseline_model_mobileV2_parameters.pth\")\ntorch.save(model, \"tumor_baseline_model_mobileV2_full.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T09:04:43.609631Z","iopub.execute_input":"2024-08-10T09:04:43.610476Z","iopub.status.idle":"2024-08-10T09:04:43.751113Z","shell.execute_reply.started":"2024-08-10T09:04:43.610442Z","shell.execute_reply":"2024-08-10T09:04:43.750269Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"As we've seen, fine-tuning a specific model for our task has rendered better results than using our own. This might not always be the case so you need to learn through trial and error, don't get discouraged as the road is long and with enough work you can be great at Deep Learning.\n\n**Good Luck!**","metadata":{}}]}